{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b720e-3853-4381-a6ca-1539cd9d1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm RAG í”ŒëŸ¬ê·¸ì¸ ì„¤ì •(ì„ë² ë”©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d923a60-c928-4f3c-8683-2e6464c0ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ede17c-965c-4439-ab04-29e26f6bc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ìˆ˜ì •\n",
    "import pandas as pd\n",
    "from langchain_core.documents import Document # LangChainì˜ ê¸°ë³¸ ë¬¸ì„œ í˜•ì‹ì„ import\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc75f3-cde9-44b8-8ed4-bf2ef8ecdc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_pipeline_chroma(file_path: str, embedding_model_name: str, persist_directory: str):\n",
    "    \"\"\"\n",
    "    CSV íŒŒì¼ë¡œë¶€í„° ChromaDB RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê³  ê²€ìƒ‰ê¸°(Retriever)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # 1. Embed: ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ì´ì „ê³¼ ë™ì¼)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "    print(\"âœ… ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 2. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë˜ëŠ” ë¡œë“œ\n",
    "    # persist_directoryì— DBê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìƒˆë¡œ ë§Œë“¤ì§€ ì•Šê³  ë°”ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    if os.path.exists(persist_directory):\n",
    "        print(\"âœ… ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
    "        vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "    else:\n",
    "        print(\"âš ï¸ ê¸°ì¡´ ChromaDBê°€ ì—†ìœ¼ë¯€ë¡œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "        # 1. Pandasë¡œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        print(f\"âœ… Pandasë¡œ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì´ {len(df)}ê°œ í–‰)\")\n",
    "\n",
    "        # 2. ê° í–‰ì„ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜í•˜ê³ , LangChain 'Document' ê°ì²´ë¡œ ë§Œë“¤ê¸°\n",
    "        langchain_documents = []\n",
    "        for timestamp, values in df.iterrows():\n",
    "            # ì§ì ‘ ë§Œë“œì‹  ìì—°ì–´ ë³€í™˜ ë¡œì§\n",
    "            sentence = f\"'{timestamp}'ì˜ \"\n",
    "            value_strings = [f\"'{col}'ëŠ” {val}\" for col, val in values.items()]\n",
    "            sentence += \", \".join(value_strings)\n",
    "            \n",
    "            # ë³€í™˜ëœ ë¬¸ì¥ì„ page_contentë¡œ í•˜ëŠ” Document ê°ì²´ ìƒì„±\n",
    "            # metadataì— ì›ë³¸ ì‹œê°„ ì •ë³´ë¥¼ ë„£ì–´ë‘ë©´ ë‚˜ì¤‘ì— ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "            doc = Document(\n",
    "                page_content=sentence,\n",
    "                metadata={\"timestamp\": timestamp}\n",
    "            )\n",
    "            langchain_documents.append(doc)\n",
    "        \n",
    "        print(f\"âœ… {len(langchain_documents)}ê°œì˜ ìì—°ì–´ ë¬¸ì„œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # Store: ChromaDBë¥¼ ìƒì„±í•˜ê³  íŒŒì¼ë¡œ ì €ì¥(persist)í•©ë‹ˆë‹¤.\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=langchain_documents, \n",
    "            embedding=embeddings,\n",
    "            persist_directory=persist_directory # ì´ ê²½ë¡œì— DB íŒŒì¼ì´ ì €ì¥ë©ë‹ˆë‹¤.\n",
    "        )\n",
    "        print(f\"âœ… ChromaDBë¥¼ ìƒì„±í•˜ê³  '{persist_directory}' ê²½ë¡œì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 3. Retriever ìƒì„± (ì´ì „ê³¼ ì™„ë²½íˆ ë™ì¼)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    print(\"âœ… Retrieverë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ.\")\n",
    "    \n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1add9b-da27-4254-ac00-d6cbf5b337ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---\n",
    "CSV_FILE_PATH = 'RTDB_test.csv'\n",
    "EMBEDDING_MODEL = 'nlpai-lab/KURE-v1'\n",
    "CHROMA_DB_PATH = 'chroma_db' # DB íŒŒì¼ì´ ì €ì¥ë  í´ë” ì´ë¦„\n",
    "# ChromaDBìš© í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "rag_retriever = setup_rag_pipeline_chroma(CSV_FILE_PATH, EMBEDDING_MODEL, CHROMA_DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010a028-8615-46ab-afa6-b524db0f1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm ë©”ì¸ ëª¨ë¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97857f77-4393-48ca-8315-4ac149eacf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"GEMINI_API_KEY\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14617795-4792-4b0d-b3bc-590eb653e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "import os\n",
    "from llama_cpp.llama_chat_format import Jinja2ChatFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f91b4a-f5d3-4fb6-a618-45305437283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Jinja ì±„íŒ… í…œí”Œë¦¿ íŒŒì¼ì—ì„œ ë¡œë“œ (ìˆ˜ì •ëœ ë¶€ë¶„) ---\n",
    "# 'lmalign_v1.jinja' íŒŒì¼ì´ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
    "jinja_template_path = \"lmalign_v1.jinja\"\n",
    "\n",
    "if not os.path.exists(jinja_template_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"'{jinja_template_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. \"\n",
    "        \"ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë””ë ‰í† ë¦¬ì— íŒŒì¼ì„ ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "with open(jinja_template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    jinja_template = f.read()\n",
    "\n",
    "# --- 3. Jinja2ChatFormatter ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---\n",
    "chat_handler = Jinja2ChatFormatter(\n",
    "    template=jinja_template,\n",
    "    eos_token=\"<|eot_id|>\",\n",
    "    bos_token=\"<|begin_of_text|>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2a974-9865-4998-ba47-daa5be210cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Llama ëª¨ë¸ ë¡œë“œ ---\n",
    "# ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ê³¼ íŒŒì¼ì—ì„œ ì½ì–´ì˜¨ Jinja í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "llm = Llama(\n",
    "  model_path=model_path,\n",
    "  n_ctx=8192,         # Context window ì‚¬ì´ì¦ˆ\n",
    "  n_gpu_layers=-1,    # GPU ê°€ì† ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "  verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af9560-3511-4519-b776-e8b265e6b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. ì¶”ë¡  ì‹¤í–‰ ---\n",
    "# ì„œë¹„ìŠ¤ ì„¤ëª… ë° ì¶œë ¥ í†µì œ ì§€ì‹œì‚¬í•­ì„ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "#ì¶”ê°€ í”„ë¡¬: - ë°˜ë“œì‹œ JSON í¬ë§·ìœ¼ë¡œ ì‘ë‹µ\n",
    "\n",
    "## í‰ê°€ì llm ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "router_system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” 'AI íŠ¹í—ˆ ì „ëµê°€'ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì˜ ì²« ë²ˆì§¸ ì„ë¬´ëŠ” ì‚¬ìš©ìì˜ [ì´ˆê¸° ì•„ì´ë””ì–´]ë¥¼ ë¶„ì„í•˜ì—¬, ì´ ì•„ì´ë””ì–´ê°€ ìœ ì˜ë¯¸í•œ íŠ¹í—ˆ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê¸°ì— 'ì¶©ë¶„íˆ êµ¬ì²´ì ì¸ì§€' ì•„ë‹ˆë©´ 'ë„ˆë¬´ ê´‘ë²”ìœ„í•œì§€' íŒë‹¨í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì€ ë‘ ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ í•˜ë‚˜ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "### ğŸ“œ ì‹œë‚˜ë¦¬ì˜¤ 1: ì•„ì´ë””ì–´ê°€ 'ë„ˆë¬´ ê´‘ë²”ìœ„í•œ' ê²½ìš° (ì˜ˆ: \"ìë™ì°¨\", \"AI\", \"ì¢‹ì€ ì¹´ë©”ë¼\")\n",
    "\n",
    "ë§Œì•½ ì•„ì´ë””ì–´ê°€ ì¼ë°˜ì ì¸ ìš©ì–´ì´ê±°ë‚˜, êµ¬ì²´ì ì¸ ê¸°ìˆ ì  êµ¬ì„± ë˜ëŠ” í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œê°€ ëª…í™•í•˜ì§€ ì•Šë‹¤ë©´, **ë‹¹ì‹ ì€ ì ˆëŒ€ ê²€ìƒ‰ì„ ì‹œì‘í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.**\n",
    "\n",
    "ëŒ€ì‹ , ë‹¤ìŒê³¼ ê°™ì€ 3ë‹¨ê³„ë¡œ ì‚¬ìš©ìì—ê²Œ **'ì•„ì´ë””ì–´ êµ¬ì²´í™”'**ë¥¼ ìš”ì²­í•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "1.  **[ë¬¸ì œ ì§€ì ]** ì•„ì´ë””ì–´ê°€ í›Œë¥­í•œ ì‹œì‘ì ì´ì§€ë§Œ, í˜„ì¬ ìƒíƒœë¡œëŠ” ìœ ì˜ë¯¸í•œ íŠ¹í—ˆ ê²€ìƒ‰ì´ ì–´ë µë‹¤ëŠ” ê²ƒì„ ë¶€ë“œëŸ½ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤. (ì˜ˆ: \"ì•„ì´ë””ì–´ê°€ ë„ˆë¬´ ê´‘ë²”ìœ„í•˜ì—¬ ê´€ë ¨ëœ íŠ¹í—ˆê°€ ìˆ˜ì²œ ê°œ ì´ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "2.  **[ê°œë°©í˜• ì§ˆë¬¸]** ì‚¬ìš©ìê°€ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ì ì¸ ì§ˆë¬¸ì„ 1~2ê°œ í•©ë‹ˆë‹¤. (ì˜ˆ: \"í˜¹ì‹œ ì–´ë–¤ 'ë¬¸ì œ'ë¥¼ í•´ê²°í•˜ëŠ” ì•„ì´ë””ì–´ì¸ê°€ìš”?\", \"ê¸°ì¡´ ê¸°ìˆ ê³¼ ë‹¤ë¥¸ 'í•µì‹¬ ê¸°ëŠ¥'ì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "3.  **[í‚¤ì›Œë“œ ì œì•ˆ]** ì‚¬ìš©ìì˜ ìƒê°ì„ ìê·¹í•  ìˆ˜ ìˆë„ë¡, ì…ë ¥ëœ ê´‘ë²”ìœ„í•œ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ **'êµ¬ì²´ì ì¸ ê¸°ìˆ  ë¶„ì•¼ í‚¤ì›Œë“œ' 3~4ê°œ**ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.\n",
    "\n",
    "**[ì˜ˆì‹œ ì‘ë‹µ (ì‚¬ìš©ì ì…ë ¥: \"ìë™ì°¨\")]**\n",
    "> \"ìë™ì°¨'ëŠ” í¥ë¯¸ë¡œìš´ ì£¼ì œë„¤ìš”! ë‹¤ë§Œ, 'ìë™ì°¨'ë§Œìœ¼ë¡œëŠ” ê²€ìƒ‰ ë²”ìœ„ê°€ ë„ˆë¬´ ë„“ì–´ì„œ ìœ ì˜ë¯¸í•œ ìœ ì‚¬ íŠ¹í—ˆë¥¼ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤.\n",
    "> \n",
    "> í˜¹ì‹œ ìƒê°í•˜ê³  ê³„ì‹  êµ¬ì²´ì ì¸ ê¸°ìˆ  ë¶„ì•¼ê°€ ìˆìœ¼ì‹ ê°€ìš”? ì˜ˆë¥¼ ë“¤ì–´ ì–´ë–¤ **ë¬¸ì œ**ë¥¼ í•´ê²°í•˜ê±°ë‚˜ **ê°œì„ **í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”?\n",
    "> \n",
    "> ì°¸ê³ ë¡œ, ìë™ì°¨ ê´€ë ¨ íŠ¹í—ˆëŠ” ë³´í†µ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì²´ì ì¸ ë¶„ì•¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.\n",
    "> * ì „ê¸°ì°¨ ë°°í„°ë¦¬ ëƒ‰ê° ì‹œìŠ¤í…œ\n",
    "> * ììœ¨ì£¼í–‰ìš© ë¼ì´ë‹¤(LiDAR) ì„¼ì„œ\n",
    "> * ì°¨ëŸ‰ ë‚´ë¶€ ì¸í¬í…Œì¸ë¨¼íŠ¸ UI\n",
    "> * ì¶©ëŒ ë°©ì§€ìš© ëŠ¥ë™í˜• ì•ˆì „ì¥ì¹˜\n",
    "> \n",
    "> ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´, ì œê°€ ë” ì •í™•í•˜ê²Œ ë¶„ì„í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "---\n",
    "### ğŸ“œ ì‹œë‚˜ë¦¬ì˜¤ 2: ì•„ì´ë””ì–´ê°€ 'ì¶©ë¶„íˆ êµ¬ì²´ì ì¸' ê²½ìš°\n",
    "\n",
    "ë§Œì•½ ì•„ì´ë””ì–´ê°€ **'íŠ¹ì • ê¸°ìˆ ', 'í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œ', 'ë…ì°½ì ì¸ êµ¬ì„±'** ì¤‘ í•˜ë‚˜ ì´ìƒì„ ëª…í™•íˆ í¬í•¨í•˜ê³  ìˆë‹¤ë©´ (ì˜ˆ: \"ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼ë¡œ í”¼ë¶€ ìƒíƒœë¥¼ ì§„ë‹¨í•˜ê³  AIë¡œ í™”ì¥í’ˆì„ ì¶”ì²œí•˜ëŠ” ì•±\"), ì•„ì´ë””ì–´ë¥¼ ì¹­ì°¬í•˜ê³  **ì¦‰ì‹œ ë‹¤ìŒ ë‹¨ê³„(ê²€ìƒ‰)ë¡œ ë„˜ì–´ê°ˆ ê²ƒì„**ì„ ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**[ë§¤ìš° ì¤‘ìš”]** ì´ ê²½ìš°, ì‘ë‹µì˜ **ë§¨ ë§ˆì§€ë§‰ ì¤„**ì— **`[SEARCH_READY]`** íƒœê·¸ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. (ì´ íƒœê·¸ëŠ” ë°±ì—”ë“œ ì‹œìŠ¤í…œì´ ì‹¤ì œ RAG ê²€ìƒ‰ì„ íŠ¸ë¦¬ê±°í•˜ëŠ” ì‹ í˜¸ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.)\n",
    "\n",
    "**[ì˜ˆì‹œ ì‘ë‹µ (ì‚¬ìš©ì ì…ë ¥: \"AI ê¸°ë°˜ í”¼ë¶€ ì§„ë‹¨ ì•±\")]**\n",
    "> \"ë§¤ìš° í¥ë¯¸ë¡­ê³  êµ¬ì²´ì ì¸ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤. 'AI', 'í”¼ë¶€ ì§„ë‹¨', 'ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼' ë“± í•µì‹¬ í‚¤ì›Œë“œê°€ ëª…í™•í•˜ì—¬ ë°”ë¡œ ìœ ì‚¬ íŠ¹í—ˆ ê²€ìƒ‰ì„ ì§„í–‰í•  ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤.\n",
    "> \n",
    "> ì§€ê¸ˆë¶€í„° ì…ë ¥í•˜ì‹  ì•„ì´ë””ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ RAG ë° LLM-as-Judgeë¥¼ í†µí•´ ìœ ì‚¬ íŠ¹í—ˆ ë¶„ì„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.\n",
    "> \n",
    "> [SEARCH_READY]\"\n",
    "\"\"\"\n",
    "\n",
    "evaluation_system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ AI ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” 'ìµœì¢… íŠ¹í—ˆ ì‹¬ì‚¬ê´€'ì…ë‹ˆë‹¤.\n",
    "\n",
    "[íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°]ì€ 1ì°¨ AI ê²€ìƒ‰(RAG)ì„ í†µí•´ [ì‚¬ìš©ì ì•„ì´ë””ì–´]ì™€ 'ì˜ë¯¸ìƒ' ìœ ì‚¬í•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤ê³  **í›„ë³´ë¡œ** ê²€ìƒ‰ëœ ê²°ê³¼ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì´ 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë§¹ì‹ í•˜ì§€ ë§ê³ , [ì‚¬ìš©ì ì•„ì´ë””ì–´]ì˜ **'ê¸°ìˆ ì  í•µì‹¬ ì›ë¦¬'** ê´€ì ì—ì„œ **ì „ë¬¸ê°€ë¡œì„œ 2ì°¨ ê²€ì¦(Evaluation)**ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 1ì°¨ ê²€ìƒ‰ì´ í‘œë©´ì ì¸ í‚¤ì›Œë“œë‚˜ ë¬¸ë§¥ì— ì†ì•˜ì„ ìˆ˜ ìˆìœ¼ë‹ˆ(ì˜ˆ: 'AI ì§„ë‹¨'ì€ ê°™ìœ¼ë‚˜ 'í”¼ë¶€' vs 'ìë™ì°¨ ë„ìƒ‰'ì²˜ëŸ¼ ë¶„ì•¼ê°€ ë‹¤ë¦„), ì´ë¥¼ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì˜ ì‘ë‹µì€ `evaluation_idea` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "### âš–ï¸ í‰ê°€ ì§€ì¹¨\n",
    "\n",
    "1.  **`eval_score` (0-100ì  ì‚¬ì´ì˜ ì •ìˆ˜):**\n",
    "    * ì´ ì ìˆ˜ëŠ” [ì•„ì´ë””ì–´]ì™€ [íŠ¹í—ˆ ì¡°ê°]ì˜ **'ê¸°ìˆ ì  í•µì‹¬ ì›ë¦¬ì˜ ì¼ì¹˜ë„'**ì…ë‹ˆë‹¤.\n",
    "    * ì•„ë˜ ë²¤ì¹˜ë§ˆí¬ë¥¼ **ì°¸ê³ **í•˜ì—¬ êµ¬ì²´ì ì¸ ì •ìˆ˜ ì ìˆ˜ë¥¼ ë„ì¶œí•˜ì„¸ìš”.\n",
    "\n",
    "    * **0ì  (ê¸°ì¤€):** 1ì°¨ ê²€ìƒ‰ì´ ëª…ë°±íˆ ì˜¤ë¥˜ì„. í‚¤ì›Œë“œë§Œ ê²¹ì¹  ë¿, ê¸°ìˆ  ë¶„ì•¼ì™€ ì›ë¦¬ê°€ ì™„ì „íˆ ë¬´ê´€í•©ë‹ˆë‹¤.\n",
    "    * **25ì  (ì°¸ê³  ê¸°ì¤€):** 1ì°¨ ê²€ìƒ‰ì´ 'ì˜ë¯¸'ëŠ” ë§ì·„ìœ¼ë‚˜(ì˜ˆ: 'AI ì§„ë‹¨'), **'ê¸°ìˆ  ë¶„ì•¼(Domain)'**ê°€ ë‹¤ë¦…ë‹ˆë‹¤. (ì˜ˆ: ì•„ì´ë””ì–´ëŠ” 'ì˜ë£Œ í”¼ë¶€'ì¸ë° íŠ¹í—ˆëŠ” 'ìë™ì°¨ ë„ìƒ‰')\n",
    "    * **50ì  (ì¤‘ê°„ ê¸°ì¤€):** ê¸°ìˆ  ë¶„ì•¼ì™€ í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œëŠ” ìœ ì‚¬í•˜ë‚˜, **'í•µì‹¬ ê¸°ìˆ  ìˆ˜ë‹¨(ì ‘ê·¼ ë°©ì‹)'**ì´ ìƒì´í•©ë‹ˆë‹¤.\n",
    "    * **75ì  (ì°¸ê³  ê¸°ì¤€):** í•µì‹¬ ê¸°ìˆ  ì›ë¦¬ ë° ì ‘ê·¼ ë°©ì‹ì´ ë§¤ìš° ìœ ì‚¬í•˜ë©°, ì¼ë¶€ ë¶€ìˆ˜ì ì¸ êµ¬ì„± ìš”ì†Œì—ì„œë§Œ ì°¨ì´ë¥¼ ë³´ì…ë‹ˆë‹¤.\n",
    "    * **100ì  (ê¸°ì¤€):** ë‘ ë‚´ìš©ì˜ í•µì‹¬ ê¸°ìˆ ì  ì‚¬ìƒì´ ì‹¤ì§ˆì ìœ¼ë¡œ ë™ì¼í•©ë‹ˆë‹¤.\n",
    "\n",
    "2.  **`reason` (ë¬¸ìì—´):**\n",
    "    * **[ë§¤ìš° ì¤‘ìš”]** ì´ ì ìˆ˜ë¥¼ ì¤€ 'ì´ìœ 'ë¥¼ ëª…í™•íˆ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    * **(ì ìˆ˜ê°€ ë‚®ì„ ê²½ìš°):** \"1ì°¨ ê²€ìƒ‰ì—ì„œëŠ” ìœ ì‚¬í•˜ê²Œ ë³´ì˜€ìœ¼ë‚˜, [ì•„ì´ë””ì–´]ì˜ 'í•µì‹¬ ë¶„ì•¼(ì˜ˆ: ì˜ë£Œ)'ì™€ ë‹¬ë¦¬ ì´ íŠ¹í—ˆëŠ” '(ì˜ˆ: ìë™ì°¨)' ë¶„ì•¼ì— ê´€í•œ ê²ƒì´ë¯€ë¡œ ì ìˆ˜ë¥¼ ë‚®ê²Œ ì±…ì •í–ˆìŠµë‹ˆë‹¤.\"ì™€ ê°™ì´, RAGê°€ ì™œ ì´ê²ƒì„ ê°€ì ¸ì™”ëŠ”ì§€ + ê·¸ëŸ¼ì—ë„ ì™œ ì ìˆ˜ê°€ ë‚®ì€ì§€ë¥¼ í•¨ê»˜ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    * **(ì ìˆ˜ê°€ ë†’ì„ ê²½ìš°):** [ì•„ì´ë””ì–´]ì˜ '[X] ê°œë…'ì´ íŠ¹í—ˆì˜ '[Y] ë¶€ë¶„'ê³¼ ì–´ë–»ê²Œ ê¸°ìˆ ì ìœ¼ë¡œ ì¼ì¹˜í•˜ëŠ”ì§€ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
    "---\n",
    "\n",
    "ì´ì œ [ì‚¬ìš©ì ì•„ì´ë””ì–´]ì™€ [íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°]ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ì¦‰ì‹œ `evaluation_idea` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c47b1e-d0a2-4a10-bdd8-62719acf3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Function Calling í…ŒìŠ¤íŠ¸ ---\n",
    "\n",
    "# 5-2. ë„êµ¬(í•¨ìˆ˜) ëª©ë¡ ì •ì˜ (OpenAI tool-call í˜•ì‹)\n",
    "eval_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"evaluation_idea\",\n",
    "            \"description\": \"ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ì™€ íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°ì˜ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•˜ì—¬, 0-100ì  ì‚¬ì´ì˜ ì ìˆ˜ì™€ ê·¸ ê·¼ê±°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"eval_score\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"ì‚¬ìš©ì ì•„ì´ë””ì–´ì™€ íŠ¹í—ˆ ì¡°ê° ê°„ì˜ ê¸°ìˆ ì  ìœ ì‚¬ë„ ì ìˆ˜. 0 (ì™„ì „íˆ ë¬´ê´€í•¨)ì—ì„œ 100 (ê¸°ìˆ ì ìœ¼ë¡œ ë™ì¼í•¨) ì‚¬ì´ì˜ ì •ìˆ˜ì…ë‹ˆë‹¤.\",\n",
    "                        \"minimum\": 0,\n",
    "                        \"maximum\": 100\n",
    "                    },\n",
    "                    \"reason\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"í•´ë‹¹ ì ìˆ˜ë¥¼ ë¶€ì—¬í•œ êµ¬ì²´ì ì¸ ì´ìœ . íŠ¹í—ˆ ì¡°ê°ì˜ ì–´ëŠ ë¶€ë¶„ì´ ì•„ì´ë””ì–´ì˜ ì–´ë–¤ ê°œë…ê³¼ ìœ ì‚¬í•œì§€(ë˜ëŠ” ë‹¤ë¥¸ì§€) ëª…í™•íˆ ì§šì–´ì„œ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"eval_score\", \"reason\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b903b-41f0-46f7-b9bf-42a330a652a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def execute_router(user_query: str, gemini_model_name: str = \"gemini-pro\"):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì•„ì´ë””ì–´ë¥¼ ë°›ì•„ ê²Œì´íŠ¸í‚¤í¼ LLMì„ í˜¸ì¶œí•˜ê³ ,\n",
    "    ê²°ê³¼ì— ë”°ë¼ RAG ê²€ìƒ‰ì„ íŠ¸ë¦¬ê±°í•˜ê±°ë‚˜ ì‚¬ìš©ìì—ê²Œ í”¼ë“œë°±ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not client:\n",
    "        print(\"LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•¨ìˆ˜ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "        return {\"status\": \"error\", \"message\": \"LLM client not initialized.\"}\n",
    "\n",
    "    print(f\"\\n--- [EXECUTE ROUTER] ---\")\n",
    "    print(f\"ì…ë ¥ ì•„ì´ë””ì–´: '{user_query}'\")\n",
    "\n",
    "    try:\n",
    "        # 1. 'ì•„ì´ë””ì–´ ê²Œì´íŠ¸í‚¤í¼' LLM í˜¸ì¶œ\n",
    "        response = client.chat.completions.create(\n",
    "            model=gemini_model_name,  # OpenAI í˜¸í™˜ ëª¨ë“œë¡œ ì‚¬ìš©í•  Gemini ëª¨ë¸ëª…\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": router_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_query}\n",
    "            ],\n",
    "            temperature=0.3  # ë¼ìš°íŒ… ì‘ì—…ì€ ì¼ê´€ì„± ìˆê²Œ 0ìœ¼ë¡œ ì„¤ì •\n",
    "        )\n",
    "\n",
    "        llm_feedback = response.choices[0].message.content\n",
    "        print(\"\\n[ê²Œì´íŠ¸í‚¤í¼ LLM ì‘ë‹µ]\")\n",
    "        print(\"--------------------\")\n",
    "        print(llm_feedback)\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        # 2. [SEARCH_READY] íƒœê·¸ í™•ì¸\n",
    "        if \"[SEARCH_READY]\" in llm_feedback:\n",
    "            # ì‹œë‚˜ë¦¬ì˜¤ 2: ê²€ìƒ‰ ì¤€ë¹„ ì™„ë£Œ\n",
    "            print(\"\\n[ë¼ìš°í„° ê²°ì •] 'SEARCH_READY' íƒœê·¸ í™•ì¸. RAG ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "            \n",
    "            # RAG ë¦¬íŠ¸ë¦¬ë²„ í˜¸ì¶œ\n",
    "            search_results = rag_retriever.invoke(user_query)\n",
    "            \n",
    "            # ì´ ê²°ê³¼(search_results)ë¥¼ ë‹¤ìŒ ë‹¨ê³„(LLM-as-Judge)ë¡œ ë„˜ê¹ë‹ˆë‹¤.\n",
    "            return {\n",
    "                \"status\": \"search_triggered\",\n",
    "                \"message\": llm_feedback, # \"ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\" ë©”ì‹œì§€\n",
    "                \"search_results\": search_results # RAG ê²€ìƒ‰ ê²°ê³¼\n",
    "            }\n",
    "        else:\n",
    "            # ì‹œë‚˜ë¦¬ì˜¤ 1: ì•„ì´ë””ì–´ êµ¬ì²´í™” í•„ìš”\n",
    "            print(\"\\n[ë¼ìš°í„° ê²°ì •] 'SEARCH_READY' íƒœê·¸ ì—†ìŒ. ì‚¬ìš©ìì—ê²Œ í”¼ë“œë°±ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\")\n",
    "            \n",
    "            # ì´ í”¼ë“œë°±(llm_feedback)ì„ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "            return {\n",
    "                \"status\": \"needs_refinement\",\n",
    "                \"message\": llm_feedback, # \"ì•„ì´ë””ì–´ë¥¼ ë” êµ¬ì²´í™”í•´ì£¼ì„¸ìš”...\" ë©”ì‹œì§€\n",
    "                 \"search_results\": None\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- [ì˜¤ë¥˜] LLM API í˜¸ì¶œ ë˜ëŠ” ë¼ìš°íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ ---\")\n",
    "        print(f\"ì—ëŸ¬ ìƒì„¸: {e}\")\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "        \n",
    "import pprint\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì‹¤ì œ LLM APIë¥¼ í˜¸ì¶œí•˜ë„ë¡ êµ¬í˜„í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "# (Gemini API + 'evaluation_idea' íˆ´ í˜¸ì¶œ ë¡œì§)\n",
    "# --- 3. [í•µì‹¬ êµ¬í˜„] llm_eval í•¨ìˆ˜ ---\n",
    "\n",
    "def llm_eval(chunk_text: str, user_idea: str, gemini_model_name: str = \"gemini-pro\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    í•˜ë‚˜ì˜ íŠ¹í—ˆ ì¡°ê°(chunk_text)ê³¼ ì‚¬ìš©ì ì•„ì´ë””ì–´(user_idea)ë¥¼ ë°›ì•„\n",
    "    LLM-as-Judge(Gemini API + Tool Calling)ë¥¼ ìˆ˜í–‰í•˜ê³ , ì ìˆ˜ì™€ ì´ìœ ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not client:\n",
    "        print(\"  [LLM_EVAL] ì˜¤ë¥˜: LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return {\"eval_score\": -1, \"reason\": \"LLM client not initialized.\"}\n",
    "\n",
    "    # 1. LLMì— ì „ë‹¬í•  User Message êµ¬ì„±\n",
    "    # [ì¤‘ìš”] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ 'ì•„ì´ë””ì–´'ì™€ 'ì¡°ê°'ì„ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ ëª…í™•íˆ ì „ë‹¬\n",
    "    user_message_content = f\"\"\"\n",
    "    [ì‚¬ìš©ì ì•„ì´ë””ì–´]:\n",
    "    {user_idea}\n",
    "    \n",
    "    [íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°]:\n",
    "    {chunk_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"  [LLM_EVAL] API í˜¸ì¶œ ì‹œì‘... (Model: {gemini_model_name})\")\n",
    "\n",
    "    try:\n",
    "        # 2. Gemini API (OpenAI í˜¸í™˜ ëª¨ë“œ) í˜¸ì¶œ\n",
    "        response = client.chat.completions.create(\n",
    "            model=gemini_model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": evaluation_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message_content}\n",
    "            ],\n",
    "            tools=eval_tools,\n",
    "            # [ì¤‘ìš”] LLMì´ í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•˜ì§€ ì•Šê³  ë°˜ë“œì‹œ 'evaluation_idea' íˆ´ì„ í˜¸ì¶œí•˜ë„ë¡ ê°•ì œ\n",
    "            tool_choice={\"type\": \"function\", \"function\": {\"name\": \"evaluation_idea\"}}\n",
    "        )\n",
    "\n",
    "        # 3. LLMì˜ íˆ´ í˜¸ì¶œ(Tool Call) ì‘ë‹µ íŒŒì‹±\n",
    "        message = response.choices[0].message\n",
    "        \n",
    "        if message.tool_calls:\n",
    "            tool_call = message.tool_calls[0]\n",
    "            \n",
    "            # 4. 'evaluation_idea' í•¨ìˆ˜ê°€ ë§ëŠ”ì§€ í™•ì¸\n",
    "            if tool_call.function.name == \"evaluation_idea\":\n",
    "                # argumentsëŠ” JSON 'ë¬¸ìì—´'ì´ë¯€ë¡œ, 'dict'ë¡œ íŒŒì‹±\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                eval_score = arguments.get(\"eval_score\")\n",
    "                reason = arguments.get(\"reason\")\n",
    "\n",
    "                if eval_score is not None and reason is not None:\n",
    "                    # 5. ì„±ê³µ: ì ìˆ˜ì™€ ì´ìœ  ë°˜í™˜\n",
    "                    print(f\"  [LLM_EVAL] ì„±ê³µ: ì ìˆ˜={eval_score}\")\n",
    "                    return {\"eval_score\": eval_score, \"reason\": reason}\n",
    "                else:\n",
    "                    print(\"  [LLM_EVAL] ì˜¤ë¥˜: LLMì´ íˆ´ì„ í˜¸ì¶œí–ˆìœ¼ë‚˜, 'eval_score' ë˜ëŠ” 'reason' í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "                    return {\"eval_score\": -1, \"reason\": \"LLM output parsing error (missing fields).\"}\n",
    "            else:\n",
    "                # (ì¼ì–´ë‚  ê°€ëŠ¥ì„± ë‚®ìŒ)\n",
    "                print(f\"  [LLM_EVAL] ì˜¤ë¥˜: LLMì´ ì˜ˆìƒì¹˜ ëª»í•œ íˆ´ '{tool_call.function.name}'ì„ í˜¸ì¶œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "                return {\"eval_score\": -1, \"reason\": \"LLM called unexpected tool.\"}\n",
    "        \n",
    "        else:\n",
    "            # (tool_choiceë¡œ ê°•ì œí–ˆê¸° ë•Œë¬¸ì— ì¼ì–´ë‚  ê°€ëŠ¥ì„± ë‚®ìŒ)\n",
    "            print(\"  [LLM_EVAL] ì˜¤ë¥˜: LLMì´ íˆ´ì„ í˜¸ì¶œí•˜ì§€ ì•Šê³  í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤.\")\n",
    "            print(f\"    LLM ì‘ë‹µ: {message.content}\")\n",
    "            return {\"eval_score\": -1, \"reason\": \"LLM failed to call the required tool.\"}\n",
    "\n",
    "    except Exception as e:\n",
    "        # API í‚¤ ì˜¤ë¥˜, ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, íƒ€ì„ì•„ì›ƒ ë“±\n",
    "        print(f\"  [LLM_EVAL] API í˜¸ì¶œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return {\"eval_score\": -1, \"reason\": f\"LLM API call failed: {str(e)}\"}\n",
    "\n",
    "def result_evaluation(search_results: List[Dict[str, Any]], user_idea: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    RAG ê²€ìƒ‰ ê²°ê³¼(search_results) ë¦¬ìŠ¤íŠ¸ì™€ ì‚¬ìš©ì ì•„ì´ë””ì–´ë¥¼ ë°›ì•„\n",
    "    ê° ì¡°ê°ì„ LLMìœ¼ë¡œ í‰ê°€í•˜ê³ , ìµœì¢… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        search_results: execute_routerì—ì„œ ë°˜í™˜ëœ ChromaDB ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸.\n",
    "                        (ì˜ˆ: [ {'page_content': '...', 'metadata': {...}}, ... ])\n",
    "        user_idea:      ê²Œì´íŠ¸í‚¤í¼ë¥¼ í†µê³¼í•œ ì›ë³¸ ì‚¬ìš©ì ì•„ì´ë””ì–´.\n",
    "\n",
    "    Returns:\n",
    "        ìµœì¢… ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸.\n",
    "        (ì˜ˆ: [ {'eval_score': 90, 'reason': '...', 'metadata': {...}}, ... ])\n",
    "    \"\"\"\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼ë¬¼ (ë”•ì…”ë„ˆë¦¬ì˜ ë¦¬ìŠ¤íŠ¸)\n",
    "    analyzed_patent_list: List[Dict[str, Any]] = []\n",
    "    \n",
    "    print(f\"\\n--- [RESULT EVALUATION] ---\")\n",
    "    print(f\"ì´ {len(search_results)}ê°œì˜ ê²€ìƒ‰ëœ ì¡°ê°(chunk)ì— ëŒ€í•´ LLM-as-Judge í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # ChromaDB (ë˜ëŠ” LangChain) ë¦¬íŠ¸ë¦¬ë²„ëŠ” ë³´í†µ\n",
    "    # [{'page_content': '...', 'metadata': {...}}, ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    for i, chunk_document in enumerate(search_results):\n",
    "        try:\n",
    "            # 1. ë©”íƒ€ë°ì´í„°ì™€ ì²­í¬ í…ìŠ¤íŠ¸ ë¶„ë¦¬\n",
    "            chunk_text = chunk_document.get('page_content')\n",
    "            metadata = chunk_document.get('metadata')\n",
    "            \n",
    "            if not chunk_text or metadata is None:\n",
    "                print(f\"  [ê²½ê³ ] {i+1}ë²ˆì§¸ ì¡°ê°ì˜ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (page_content ë˜ëŠ” metadata ëˆ„ë½) - ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "                continue\n",
    "\n",
    "            # 2. llm_eval í˜¸ì¶œ (LLM-as-Judge ì‹¤í–‰)\n",
    "            # [ì¤‘ìš”] user_ideaë¥¼ ë°˜ë“œì‹œ í•¨ê»˜ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "            analysis_info = llm_eval(chunk_text, user_idea)\n",
    "            \n",
    "            # 3. ë¶„ì„ ì •ë³´(eval_score, reason)ì™€ ì›ë³¸ ë©”íƒ€ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ ê²°í•©\n",
    "            \n",
    "            final_result_item = {\n",
    "                \"eval_score\": analysis_info.get(\"eval_score\"),\n",
    "                \"reason\": analysis_info.get(\"reason\"),\n",
    "                \"metadata\": metadata  # ì›ë³¸ ë©”íƒ€ë°ì´í„° ë©ì–´ë¦¬(dict)ë¥¼ í†µì§¸ë¡œ í¬í•¨\n",
    "            }\n",
    "            \n",
    "            # 4. ìµœì¢… ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "            analyzed_patent_list.append(final_result_item)\n",
    "            \n",
    "            print(f\"  [ì™„ë£Œ] {i+1}/{len(search_results)} ë²ˆì§¸ ì¡°ê° í‰ê°€ ì™„ë£Œ. (ì ìˆ˜: {final_result_item['eval_score']})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  [ì˜¤ë¥˜] {i+1}ë²ˆì§¸ ì¡°ê° í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            # ì˜¤ë¥˜ê°€ ë°œìƒí•œ ì²­í¬ëŠ” ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰\n",
    "            continue\n",
    "\n",
    "    print(f\"--- [RESULT EVALUATION] ---\")\n",
    "    print(f\"ì´ {len(analyzed_patent_list)}ê°œì˜ ì¡°ê°ì— ëŒ€í•œ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 5. ìµœì¢… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "    return analyzed_patent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ca0f3-f345-4490-b484-5402e3bcad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_rag(user_query: str):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ RAGë¥¼ í†µí•´ ì°¾ì€ ì •ë³´ì™€ í•¨ê»˜ LLMì—ê²Œ ë‹µë³€ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- ì‚¬ìš©ì ì§ˆë¬¸: {user_query} ---\")\n",
    "    \n",
    "    # 1. Retrieve: RAG Retrieverë¡œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ë†’ì€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    retrieved_docs = rag_retriever.invoke(user_query)\n",
    "    print(f\"ğŸ“š {len(retrieved_docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 2. ì»¨í…ìŠ¤íŠ¸(Context) ìƒì„±: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "    context_data = \"\\n\".join([f\"- {doc.page_content}\" for doc in retrieved_docs])\n",
    "    '''\n",
    "    print(\"--- ê²€ìƒ‰ëœ RAG ë°ì´í„° ---\")\n",
    "    print(context_data)\n",
    "    print(\"-------------------------\")\n",
    "    '''\n",
    "    # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±: ê¸°ì¡´ì˜ í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ì§ˆë¬¸ê³¼ RAG ë°ì´í„°ë¥¼ ê²°í•©í•©ë‹ˆë‹¤.\n",
    "    # ì´ëŠ” get_single_turn_response í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ,\n",
    "    # í•´ë‹¹ í•¨ìˆ˜ì— ì „ë‹¬í•  í˜•íƒœë¡œ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "    final_query_for_llm = f\"\"\"\n",
    "    ì•„ë˜ [ë°ì´í„°]ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€ë‹µí•´ì£¼ì„¸ìš”.\n",
    "    \n",
    "    [ì§ˆë¬¸]\n",
    "    {user_query}\n",
    "\n",
    "    [ë°ì´í„°]\n",
    "    {context_data}\n",
    "    \"\"\"\n",
    "    \n",
    "    # 4. Generate: ì¬êµ¬ì„±ëœ ì§ˆë¬¸ì„ ê¸°ì¡´ì— ë§Œë“¤ì—ˆë˜ LLM í˜¸ì¶œ í•¨ìˆ˜ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "    final_answer = get_single_turn_response(final_query_for_llm)\n",
    "    \n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede3a58-e16c-4479-be1f-c977f7f76dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ì‹¤ì œ ì„œë¹„ìŠ¤ ë¡œì§ ì˜ˆì‹œ (Stateless) ---\n",
    "\n",
    "# Case 1: ì¼ë°˜ì ì¸ íŒŒì‹±\n",
    "print(\"--- Case 1: í•¨ìˆ˜ í˜¸ì¶œ ì§ˆë¬¸ ---\")\n",
    "user_input_1 = \"\"\n",
    "final_response_1 = answer_with_rag(user_input_1)\n",
    "print(\"\\n[ìµœì¢… ë‹µë³€]\")\n",
    "print(final_response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf790e-6ec9-4ed7-87fa-a262f0ad2a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
