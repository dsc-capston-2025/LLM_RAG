{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b720e-3853-4381-a6ca-1539cd9d1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm RAG í”ŒëŸ¬ê·¸ì¸ ì„¤ì •(ì„ë² ë”©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d923a60-c928-4f3c-8683-2e6464c0ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ede17c-965c-4439-ab04-29e26f6bc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ìˆ˜ì •\n",
    "import pandas as pd\n",
    "from langchain_core.documents import Document # LangChainì˜ ê¸°ë³¸ ë¬¸ì„œ í˜•ì‹ì„ import\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc75f3-cde9-44b8-8ed4-bf2ef8ecdc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_pipeline_chroma(file_path: str, embedding_model_name: str, persist_directory: str):\n",
    "    \"\"\"\n",
    "    CSV íŒŒì¼ë¡œë¶€í„° ChromaDB RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê³  ê²€ìƒ‰ê¸°(Retriever)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # 1. Embed: ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ì´ì „ê³¼ ë™ì¼)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "    print(\"âœ… ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 2. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë˜ëŠ” ë¡œë“œ\n",
    "    # persist_directoryì— DBê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìƒˆë¡œ ë§Œë“¤ì§€ ì•Šê³  ë°”ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    if os.path.exists(persist_directory):\n",
    "        print(\"âœ… ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
    "        vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "    else:\n",
    "        print(\"âš ï¸ ê¸°ì¡´ ChromaDBê°€ ì—†ìœ¼ë¯€ë¡œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "        # 1. Pandasë¡œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        print(f\"âœ… Pandasë¡œ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì´ {len(df)}ê°œ í–‰)\")\n",
    "\n",
    "        # 2. ê° í–‰ì„ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜í•˜ê³ , LangChain 'Document' ê°ì²´ë¡œ ë§Œë“¤ê¸°\n",
    "        langchain_documents = []\n",
    "        for timestamp, values in df.iterrows():\n",
    "            # ì§ì ‘ ë§Œë“œì‹  ìì—°ì–´ ë³€í™˜ ë¡œì§\n",
    "            sentence = f\"'{timestamp}'ì˜ \"\n",
    "            value_strings = [f\"'{col}'ëŠ” {val}\" for col, val in values.items()]\n",
    "            sentence += \", \".join(value_strings)\n",
    "            \n",
    "            # ë³€í™˜ëœ ë¬¸ì¥ì„ page_contentë¡œ í•˜ëŠ” Document ê°ì²´ ìƒì„±\n",
    "            # metadataì— ì›ë³¸ ì‹œê°„ ì •ë³´ë¥¼ ë„£ì–´ë‘ë©´ ë‚˜ì¤‘ì— ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "            doc = Document(\n",
    "                page_content=sentence,\n",
    "                metadata={\"timestamp\": timestamp}\n",
    "            )\n",
    "            langchain_documents.append(doc)\n",
    "        \n",
    "        print(f\"âœ… {len(langchain_documents)}ê°œì˜ ìì—°ì–´ ë¬¸ì„œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # Store: ChromaDBë¥¼ ìƒì„±í•˜ê³  íŒŒì¼ë¡œ ì €ì¥(persist)í•©ë‹ˆë‹¤.\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=langchain_documents, \n",
    "            embedding=embeddings,\n",
    "            persist_directory=persist_directory # ì´ ê²½ë¡œì— DB íŒŒì¼ì´ ì €ì¥ë©ë‹ˆë‹¤.\n",
    "        )\n",
    "        print(f\"âœ… ChromaDBë¥¼ ìƒì„±í•˜ê³  '{persist_directory}' ê²½ë¡œì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 3. Retriever ìƒì„± (ì´ì „ê³¼ ì™„ë²½íˆ ë™ì¼)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    print(\"âœ… Retrieverë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ.\")\n",
    "    \n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1add9b-da27-4254-ac00-d6cbf5b337ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---\n",
    "CSV_FILE_PATH = 'RTDB_test.csv'\n",
    "EMBEDDING_MODEL = 'nlpai-lab/KURE-v1'\n",
    "CHROMA_DB_PATH = 'chroma_db' # DB íŒŒì¼ì´ ì €ì¥ë  í´ë” ì´ë¦„\n",
    "# ChromaDBìš© í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "rag_retriever = setup_rag_pipeline_chroma(CSV_FILE_PATH, EMBEDDING_MODEL, CHROMA_DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010a028-8615-46ab-afa6-b524db0f1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm ë©”ì¸ ëª¨ë¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97857f77-4393-48ca-8315-4ac149eacf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"GEMINI_API_KEY\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14617795-4792-4b0d-b3bc-590eb653e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "import os\n",
    "from llama_cpp.llama_chat_format import Jinja2ChatFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f91b4a-f5d3-4fb6-a618-45305437283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Jinja ì±„íŒ… í…œí”Œë¦¿ íŒŒì¼ì—ì„œ ë¡œë“œ (ìˆ˜ì •ëœ ë¶€ë¶„) ---\n",
    "# 'lmalign_v1.jinja' íŒŒì¼ì´ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
    "jinja_template_path = \"lmalign_v1.jinja\"\n",
    "\n",
    "if not os.path.exists(jinja_template_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"'{jinja_template_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. \"\n",
    "        \"ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë””ë ‰í† ë¦¬ì— íŒŒì¼ì„ ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "with open(jinja_template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    jinja_template = f.read()\n",
    "\n",
    "# --- 3. Jinja2ChatFormatter ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---\n",
    "chat_handler = Jinja2ChatFormatter(\n",
    "    template=jinja_template,\n",
    "    eos_token=\"<|eot_id|>\",\n",
    "    bos_token=\"<|begin_of_text|>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2a974-9865-4998-ba47-daa5be210cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Llama ëª¨ë¸ ë¡œë“œ ---\n",
    "# ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ê³¼ íŒŒì¼ì—ì„œ ì½ì–´ì˜¨ Jinja í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "llm = Llama(\n",
    "  model_path=model_path,\n",
    "  n_ctx=8192,         # Context window ì‚¬ì´ì¦ˆ\n",
    "  n_gpu_layers=-1,    # GPU ê°€ì† ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "  verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af9560-3511-4519-b776-e8b265e6b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. ì¶”ë¡  ì‹¤í–‰ ---\n",
    "# ì„œë¹„ìŠ¤ ì„¤ëª… ë° ì¶œë ¥ í†µì œ ì§€ì‹œì‚¬í•­ì„ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "#ì¶”ê°€ í”„ë¡¬: - ë°˜ë“œì‹œ JSON í¬ë§·ìœ¼ë¡œ ì‘ë‹µ\n",
    "\n",
    "## í‰ê°€ì llm ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "router_system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” 'AI íŠ¹í—ˆ ì „ëµê°€'ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì˜ ì²« ë²ˆì§¸ ì„ë¬´ëŠ” ì‚¬ìš©ìì˜ [ì´ˆê¸° ì•„ì´ë””ì–´]ë¥¼ ë¶„ì„í•˜ì—¬, ì´ ì•„ì´ë””ì–´ê°€ ìœ ì˜ë¯¸í•œ íŠ¹í—ˆ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê¸°ì— 'ì¶©ë¶„íˆ êµ¬ì²´ì ì¸ì§€' ì•„ë‹ˆë©´ 'ë„ˆë¬´ ê´‘ë²”ìœ„í•œì§€' íŒë‹¨í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì€ ë‘ ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ í•˜ë‚˜ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "### ğŸ“œ ì‹œë‚˜ë¦¬ì˜¤ 1: ì•„ì´ë””ì–´ê°€ 'ë„ˆë¬´ ê´‘ë²”ìœ„í•œ' ê²½ìš° (ì˜ˆ: \"ìë™ì°¨\", \"AI\", \"ì¢‹ì€ ì¹´ë©”ë¼\")\n",
    "\n",
    "ë§Œì•½ ì•„ì´ë””ì–´ê°€ ì¼ë°˜ì ì¸ ìš©ì–´ì´ê±°ë‚˜, êµ¬ì²´ì ì¸ ê¸°ìˆ ì  êµ¬ì„± ë˜ëŠ” í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œê°€ ëª…í™•í•˜ì§€ ì•Šë‹¤ë©´, **ë‹¹ì‹ ì€ ì ˆëŒ€ ê²€ìƒ‰ì„ ì‹œì‘í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.**\n",
    "\n",
    "ëŒ€ì‹ , ë‹¤ìŒê³¼ ê°™ì€ 3ë‹¨ê³„ë¡œ ì‚¬ìš©ìì—ê²Œ **'ì•„ì´ë””ì–´ êµ¬ì²´í™”'**ë¥¼ ìš”ì²­í•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "1.  **[ë¬¸ì œ ì§€ì ]** ì•„ì´ë””ì–´ê°€ í›Œë¥­í•œ ì‹œì‘ì ì´ì§€ë§Œ, í˜„ì¬ ìƒíƒœë¡œëŠ” ìœ ì˜ë¯¸í•œ íŠ¹í—ˆ ê²€ìƒ‰ì´ ì–´ë µë‹¤ëŠ” ê²ƒì„ ë¶€ë“œëŸ½ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤. (ì˜ˆ: \"ì•„ì´ë””ì–´ê°€ ë„ˆë¬´ ê´‘ë²”ìœ„í•˜ì—¬ ê´€ë ¨ëœ íŠ¹í—ˆê°€ ìˆ˜ì²œ ê°œ ì´ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "2.  **[ê°œë°©í˜• ì§ˆë¬¸]** ì‚¬ìš©ìê°€ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ì ì¸ ì§ˆë¬¸ì„ 1~2ê°œ í•©ë‹ˆë‹¤. (ì˜ˆ: \"í˜¹ì‹œ ì–´ë–¤ 'ë¬¸ì œ'ë¥¼ í•´ê²°í•˜ëŠ” ì•„ì´ë””ì–´ì¸ê°€ìš”?\", \"ê¸°ì¡´ ê¸°ìˆ ê³¼ ë‹¤ë¥¸ 'í•µì‹¬ ê¸°ëŠ¥'ì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "3.  **[í‚¤ì›Œë“œ ì œì•ˆ]** ì‚¬ìš©ìì˜ ìƒê°ì„ ìê·¹í•  ìˆ˜ ìˆë„ë¡, ì…ë ¥ëœ ê´‘ë²”ìœ„í•œ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ **'êµ¬ì²´ì ì¸ ê¸°ìˆ  ë¶„ì•¼ í‚¤ì›Œë“œ' 3~4ê°œ**ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.\n",
    "\n",
    "**[ì˜ˆì‹œ ì‘ë‹µ (ì‚¬ìš©ì ì…ë ¥: \"ìë™ì°¨\")]**\n",
    "> \"ìë™ì°¨'ëŠ” í¥ë¯¸ë¡œìš´ ì£¼ì œë„¤ìš”! ë‹¤ë§Œ, 'ìë™ì°¨'ë§Œìœ¼ë¡œëŠ” ê²€ìƒ‰ ë²”ìœ„ê°€ ë„ˆë¬´ ë„“ì–´ì„œ ìœ ì˜ë¯¸í•œ ìœ ì‚¬ íŠ¹í—ˆë¥¼ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤.\n",
    "> \n",
    "> í˜¹ì‹œ ìƒê°í•˜ê³  ê³„ì‹  êµ¬ì²´ì ì¸ ê¸°ìˆ  ë¶„ì•¼ê°€ ìˆìœ¼ì‹ ê°€ìš”? ì˜ˆë¥¼ ë“¤ì–´ ì–´ë–¤ **ë¬¸ì œ**ë¥¼ í•´ê²°í•˜ê±°ë‚˜ **ê°œì„ **í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”?\n",
    "> \n",
    "> ì°¸ê³ ë¡œ, ìë™ì°¨ ê´€ë ¨ íŠ¹í—ˆëŠ” ë³´í†µ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì²´ì ì¸ ë¶„ì•¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.\n",
    "> * ì „ê¸°ì°¨ ë°°í„°ë¦¬ ëƒ‰ê° ì‹œìŠ¤í…œ\n",
    "> * ììœ¨ì£¼í–‰ìš© ë¼ì´ë‹¤(LiDAR) ì„¼ì„œ\n",
    "> * ì°¨ëŸ‰ ë‚´ë¶€ ì¸í¬í…Œì¸ë¨¼íŠ¸ UI\n",
    "> * ì¶©ëŒ ë°©ì§€ìš© ëŠ¥ë™í˜• ì•ˆì „ì¥ì¹˜\n",
    "> \n",
    "> ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´, ì œê°€ ë” ì •í™•í•˜ê²Œ ë¶„ì„í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "---\n",
    "### ğŸ“œ ì‹œë‚˜ë¦¬ì˜¤ 2: ì•„ì´ë””ì–´ê°€ 'ì¶©ë¶„íˆ êµ¬ì²´ì ì¸' ê²½ìš°\n",
    "\n",
    "ë§Œì•½ ì•„ì´ë””ì–´ê°€ **'íŠ¹ì • ê¸°ìˆ ', 'í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œ', 'ë…ì°½ì ì¸ êµ¬ì„±'** ì¤‘ í•˜ë‚˜ ì´ìƒì„ ëª…í™•íˆ í¬í•¨í•˜ê³  ìˆë‹¤ë©´ (ì˜ˆ: \"ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼ë¡œ í”¼ë¶€ ìƒíƒœë¥¼ ì§„ë‹¨í•˜ê³  AIë¡œ í™”ì¥í’ˆì„ ì¶”ì²œí•˜ëŠ” ì•±\"), ì•„ì´ë””ì–´ë¥¼ ì¹­ì°¬í•˜ê³  **ì¦‰ì‹œ ë‹¤ìŒ ë‹¨ê³„(ê²€ìƒ‰)ë¡œ ë„˜ì–´ê°ˆ ê²ƒì„**ì„ ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**[ë§¤ìš° ì¤‘ìš”]** ì´ ê²½ìš°, ì‘ë‹µì˜ **ë§¨ ë§ˆì§€ë§‰ ì¤„**ì— **`[SEARCH_READY]`** íƒœê·¸ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. (ì´ íƒœê·¸ëŠ” ë°±ì—”ë“œ ì‹œìŠ¤í…œì´ ì‹¤ì œ RAG ê²€ìƒ‰ì„ íŠ¸ë¦¬ê±°í•˜ëŠ” ì‹ í˜¸ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.)\n",
    "\n",
    "**[ì˜ˆì‹œ ì‘ë‹µ (ì‚¬ìš©ì ì…ë ¥: \"AI ê¸°ë°˜ í”¼ë¶€ ì§„ë‹¨ ì•±\")]**\n",
    "> \"ë§¤ìš° í¥ë¯¸ë¡­ê³  êµ¬ì²´ì ì¸ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤. 'AI', 'í”¼ë¶€ ì§„ë‹¨', 'ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼' ë“± í•µì‹¬ í‚¤ì›Œë“œê°€ ëª…í™•í•˜ì—¬ ë°”ë¡œ ìœ ì‚¬ íŠ¹í—ˆ ê²€ìƒ‰ì„ ì§„í–‰í•  ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤.\n",
    "> \n",
    "> ì§€ê¸ˆë¶€í„° ì…ë ¥í•˜ì‹  ì•„ì´ë””ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ RAG ë° LLM-as-Judgeë¥¼ í†µí•´ ìœ ì‚¬ íŠ¹í—ˆ ë¶„ì„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.\n",
    "> \n",
    "> [SEARCH_READY]\"\n",
    "\"\"\"\n",
    "\n",
    "evaluation_system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ ê³ ë„ë¡œ ì „ë¬¸í™”ëœ íŠ¹í—ˆ ì‹¬ì‚¬ê´€ì´ì ê¸°ìˆ  ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” [ì‚¬ìš©ì ì•„ì´ë””ì–´]ì™€ [íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°]ì„ ì…ë ¥ë°›ì•„, ë‘ ë‚´ìš©ì˜ ê¸°ìˆ ì  ìœ ì‚¬ì„±ì„ ì •ë°€í•˜ê²Œ ë¶„ì„í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ ë³´ê³ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì€ **ì ˆëŒ€** ì¼ë°˜ì ì¸ ëŒ€í™”í˜• í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ë‹¹ì‹ ì˜ **ìœ ì¼í•œ** ì‘ë‹µì€ `evaluation_idea` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "### âš–ï¸ í‰ê°€ ì§€ì¹¨\n",
    "\n",
    "ë‹¹ì‹ ì€ ë‹¤ìŒì˜ ì—„ê²©í•œ ê¸°ì¤€ì— ë”°ë¼ [ì‚¬ìš©ì ì•„ì´ë””ì–´]ì™€ [íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°]ì„ ë¹„êµí•˜ê³ , `evaluation_idea` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "1.  **`eval_score` (0-100ì  ì‚¬ì´ì˜ ì •ìˆ˜):**\n",
    "    * `eval_score`ëŠ” **0ì ì—ì„œ 100ì  ì‚¬ì´ì˜ ëª¨ë“  ì •ìˆ˜(integer)**ë¡œ í‰ê°€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: 65ì , 82ì , 91ì )\n",
    "    * ì•„ë˜ì˜ ì ìˆ˜ ë²¤ì¹˜ë§ˆí¬ëŠ” **íŒë‹¨ì˜ ê¸°ì¤€ì„ (Benchmark)**ì…ë‹ˆë‹¤. ì´ ê¸°ì¤€ì„ **ì°¸ê³ **í•˜ì—¬, ë‘ ë‚´ìš©ì˜ ìœ ì‚¬ë„ì— ê°€ì¥ ì í•©í•˜ë‹¤ê³  íŒë‹¨ë˜ëŠ” **êµ¬ì²´ì ì¸ ì •ìˆ˜ ì ìˆ˜**ë¥¼ ë„ì¶œí•˜ì„¸ìš”.\n",
    "\n",
    "    * **0ì  (ê¸°ì¤€):** [ì•„ì´ë””ì–´]ì™€ [íŠ¹í—ˆ ì¡°ê°]ì´ ê¸°ìˆ ì ìœ¼ë¡œ ì™„ì „íˆ ë¬´ê´€í•©ë‹ˆë‹¤.\n",
    "    * **25ì  (ì°¸ê³  ê¸°ì¤€):** ì¼ë¶€ í‚¤ì›Œë“œëŠ” ê²¹ì¹˜ë‚˜, í•µì‹¬ ê¸°ìˆ  ì›ë¦¬ë‚˜ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œê°€ ë‹¤ë¦…ë‹ˆë‹¤.\n",
    "    * **50ì  (ì¤‘ê°„ ê¸°ì¤€):** ìœ ì‚¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ í•˜ë‚˜, ì‚¬ìš©ëœ ê¸°ìˆ ì  ì ‘ê·¼ ë°©ì‹ì´ë‚˜ í•µì‹¬ êµ¬ì„±ì´ ìƒì´í•©ë‹ˆë‹¤.\n",
    "    * **75ì  (ì°¸K ê¸°ì¤€):** í•µì‹¬ ê¸°ìˆ  ì›ë¦¬ ë° ì ‘ê·¼ ë°©ì‹ì´ ë§¤ìš° ìœ ì‚¬í•˜ë©°, ì¼ë¶€ ì‚¬ì†Œí•œ êµ¬ì„± ìš”ì†Œë‚˜ ì ìš© ë²”ìœ„ì—ì„œë§Œ ì°¨ì´ë¥¼ ë³´ì…ë‹ˆë‹¤.\n",
    "    * **100ì  (ê¸°ì¤€):** ë‘ ë‚´ìš©ì˜ í•µì‹¬ ê¸°ìˆ ì  ì‚¬ìƒ(ë°œëª…ì˜ ì›ë¦¬)ì´ ì‹¤ì§ˆì ìœ¼ë¡œ ë™ì¼í•˜ê±°ë‚˜ ëª…ë°±í•œ ë™ë“±ë¬¼ì…ë‹ˆë‹¤.\n",
    "\n",
    "2.  **`reason` (ë¬¸ìì—´):**\n",
    "    * í•´ë‹¹ `eval_score`ë¥¼ ë¶€ì—¬í•œ ëª…í™•í•˜ê³  ì „ë¬¸ê°€ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    * **[ë§¤ìš° ì¤‘ìš”]** [ì‚¬ìš©ì ì•„ì´ë””ì–´]ì˜ **'ì–´ë–¤ ê°œë…'**ì´ [íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°]ì˜ **'ì–´ëŠ íŠ¹ì • ë¶€ë¶„(ë¬¸êµ¬ ì¸ìš© ê°€ëŠ¥)'**ê³¼ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ ìœ ì‚¬í•œì§€ (ë˜ëŠ” ë‹¤ë¥¸ì§€) ë°˜ë“œì‹œ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    * ì¶”ìƒì ì¸ ì„¤ëª…ì´ ì•„ë‹Œ, êµ¬ì²´ì ì¸ ë¹„êµ ë¶„ì„ ë‚´ìš©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "---\n",
    "\n",
    "ì´ì œ [ì‚¬ìš©ì ì•„ì´ë””ì–´]ì™€ [íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°]ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ì¦‰ì‹œ `evaluation_idea` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c47b1e-d0a2-4a10-bdd8-62719acf3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Function Calling í…ŒìŠ¤íŠ¸ ---\n",
    "\n",
    "# 5-1. íŒŒì´ì¬ í•¨ìˆ˜ ì •ì˜\n",
    "# '-> float'ëŠ” ì´ í•¨ìˆ˜ê°€ ìˆ«ì(float)ë¥¼ ë°˜í™˜í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ëŠ” íƒ€ì… íŒíŠ¸ì…ë‹ˆë‹¤.\n",
    "def calculate_average(val1: float, val2: float) -> float:\n",
    "    \"\"\"ë‘ ê°œì˜ ìˆ«ì ê°’ì˜ ì‚°ìˆ  í‰ê· ì„ ê³„ì‚°í•˜ê³ , ê·¸ ìˆ«ì ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        average = (val1 + val2) / 2\n",
    "        print(f\"--- 'calculate_average' í˜¸ì¶œë¨ (val1={val1}, val2={val2}), ê²°ê³¼: {average} ---\")\n",
    "        return average # ğŸ‘ˆ ë¬¸ì¥ ëŒ€ì‹  ìˆ«ì ê°’ì„ ì§ì ‘ ë°˜í™˜\n",
    "    except TypeError:\n",
    "        return 0.0 # ì˜¤ë¥˜ ë°œìƒ ì‹œ 0.0 ë°˜í™˜\n",
    "\n",
    "# 5-2. ë„êµ¬(í•¨ìˆ˜) ëª©ë¡ ì •ì˜ (OpenAI tool-call í˜•ì‹)\n",
    "eval_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"evaluation_idea\",\n",
    "            \"description\": \"ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ì™€ íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°ì˜ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•˜ì—¬, 0-100ì  ì‚¬ì´ì˜ ì ìˆ˜ì™€ ê·¸ ê·¼ê±°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"eval_score\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"ì‚¬ìš©ì ì•„ì´ë””ì–´ì™€ íŠ¹í—ˆ ì¡°ê° ê°„ì˜ ê¸°ìˆ ì  ìœ ì‚¬ë„ ì ìˆ˜. 0 (ì™„ì „íˆ ë¬´ê´€í•¨)ì—ì„œ 100 (ê¸°ìˆ ì ìœ¼ë¡œ ë™ì¼í•¨) ì‚¬ì´ì˜ ì •ìˆ˜ì…ë‹ˆë‹¤.\",\n",
    "                        \"minimum\": 0,\n",
    "                        \"maximum\": 100\n",
    "                    },\n",
    "                    \"reason\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"í•´ë‹¹ ì ìˆ˜ë¥¼ ë¶€ì—¬í•œ êµ¬ì²´ì ì¸ ì´ìœ . íŠ¹í—ˆ ì¡°ê°ì˜ ì–´ëŠ ë¶€ë¶„ì´ ì•„ì´ë””ì–´ì˜ ì–´ë–¤ ê°œë…ê³¼ ìœ ì‚¬í•œì§€(ë˜ëŠ” ë‹¤ë¥¸ì§€) ëª…í™•íˆ ì§šì–´ì„œ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"eval_score\", \"reason\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b903b-41f0-46f7-b9bf-42a330a652a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def execute_router(user_query: str, gemini_model_name: str = \"gemini-pro\"):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì•„ì´ë””ì–´ë¥¼ ë°›ì•„ ê²Œì´íŠ¸í‚¤í¼ LLMì„ í˜¸ì¶œí•˜ê³ ,\n",
    "    ê²°ê³¼ì— ë”°ë¼ RAG ê²€ìƒ‰ì„ íŠ¸ë¦¬ê±°í•˜ê±°ë‚˜ ì‚¬ìš©ìì—ê²Œ í”¼ë“œë°±ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not client:\n",
    "        print(\"LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•¨ìˆ˜ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "        return {\"status\": \"error\", \"message\": \"LLM client not initialized.\"}\n",
    "\n",
    "    print(f\"\\n--- [EXECUTE ROUTER] ---\")\n",
    "    print(f\"ì…ë ¥ ì•„ì´ë””ì–´: '{user_query}'\")\n",
    "\n",
    "    try:\n",
    "        # 1. 'ì•„ì´ë””ì–´ ê²Œì´íŠ¸í‚¤í¼' LLM í˜¸ì¶œ\n",
    "        response = client.chat.completions.create(\n",
    "            model=gemini_model_name,  # OpenAI í˜¸í™˜ ëª¨ë“œë¡œ ì‚¬ìš©í•  Gemini ëª¨ë¸ëª…\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": router_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_query}\n",
    "            ],\n",
    "            temperature=0.3  # ë¼ìš°íŒ… ì‘ì—…ì€ ì¼ê´€ì„± ìˆê²Œ 0ìœ¼ë¡œ ì„¤ì •\n",
    "        )\n",
    "\n",
    "        llm_feedback = response.choices[0].message.content\n",
    "        print(\"\\n[ê²Œì´íŠ¸í‚¤í¼ LLM ì‘ë‹µ]\")\n",
    "        print(\"--------------------\")\n",
    "        print(llm_feedback)\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        # 2. [SEARCH_READY] íƒœê·¸ í™•ì¸\n",
    "        if \"[SEARCH_READY]\" in llm_feedback:\n",
    "            # ì‹œë‚˜ë¦¬ì˜¤ 2: ê²€ìƒ‰ ì¤€ë¹„ ì™„ë£Œ\n",
    "            print(\"\\n[ë¼ìš°í„° ê²°ì •] 'SEARCH_READY' íƒœê·¸ í™•ì¸. RAG ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "            \n",
    "            # RAG ë¦¬íŠ¸ë¦¬ë²„ í˜¸ì¶œ\n",
    "            search_results = rag_retriever.invoke(user_query)\n",
    "            \n",
    "            # ì´ ê²°ê³¼(search_results)ë¥¼ ë‹¤ìŒ ë‹¨ê³„(LLM-as-Judge)ë¡œ ë„˜ê¹ë‹ˆë‹¤.\n",
    "            return {\n",
    "                \"status\": \"search_triggered\",\n",
    "                \"message\": llm_feedback, # \"ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\" ë©”ì‹œì§€\n",
    "                \"search_results\": search_results # RAG ê²€ìƒ‰ ê²°ê³¼\n",
    "            }\n",
    "        else:\n",
    "            # ì‹œë‚˜ë¦¬ì˜¤ 1: ì•„ì´ë””ì–´ êµ¬ì²´í™” í•„ìš”\n",
    "            print(\"\\n[ë¼ìš°í„° ê²°ì •] 'SEARCH_READY' íƒœê·¸ ì—†ìŒ. ì‚¬ìš©ìì—ê²Œ í”¼ë“œë°±ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\")\n",
    "            \n",
    "            # ì´ í”¼ë“œë°±(llm_feedback)ì„ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "            return {\n",
    "                \"status\": \"needs_refinement\",\n",
    "                \"message\": llm_feedback # \"ì•„ì´ë””ì–´ë¥¼ ë” êµ¬ì²´í™”í•´ì£¼ì„¸ìš”...\" ë©”ì‹œì§€\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- [ì˜¤ë¥˜] LLM API í˜¸ì¶œ ë˜ëŠ” ë¼ìš°íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ ---\")\n",
    "        print(f\"ì—ëŸ¬ ìƒì„¸: {e}\")\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "def execute_llm_turn(messages: list, max_depth: int = 5):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡(messages)ì„ ë°”íƒ•ìœ¼ë¡œ LLMì„ 1íšŒ í˜¸ì¶œí•˜ê³ ,\n",
    "    ê·¸ ê²°ê³¼ê°€ í•¨ìˆ˜ í˜¸ì¶œì´ë©´ ì¬ê·€ì ìœ¼ë¡œ ìì‹ ì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ëŠ” í•µì‹¬ í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    # 1. ì¬ê·€ í˜¸ì¶œì˜ ì•ˆì „ì¥ì¹˜: ìµœëŒ€ í˜¸ì¶œ íšŸìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜\n",
    "    if max_depth <= 0:\n",
    "        return \"ìµœëŒ€ í•¨ìˆ˜ í˜¸ì¶œ íšŸìˆ˜ë¥¼ ì´ˆê³¼í•˜ì—¬ ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "    # 2. ì£¼ì–´ì§„ messagesë¡œ LLM ì¶”ë¡  ì‹¤í–‰ (ì½”ë“œ ì¤‘ë³µ ì œê±°)\n",
    "    prompt_response = chat_handler(messages=messages, tools=tools)\n",
    "    response = llm.create_completion(\n",
    "        prompt=prompt_response.prompt,\n",
    "        max_tokens=2048,\n",
    "        stop=prompt_response.stop,\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    reasoning_effort=\"medium\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": evaluation_system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"[ì‚¬ìš©ì ì•„ì´ë””ì–´]: {user_idea}\\n [íŠ¹í—ˆ ë¬¸ì„œ ì¡°ê°]: {doc_chunk}\"\n",
    "        }\n",
    "    ],\n",
    "    tools=eval_tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "    output_text = response['choices'][0]['text'].strip()\n",
    "\n",
    "    # 3. LLMì˜ ì‘ë‹µì—ì„œ í•¨ìˆ˜ í˜¸ì¶œ íŒ¨í„´ í™•ì¸\n",
    "    match = re.search(r\"<function=.*?</function>\", output_text)\n",
    "\n",
    "    # 4. ì¬ê·€ì˜ ë¶„ê¸°ì : í•¨ìˆ˜ í˜¸ì¶œì´ ìˆëŠ”ì§€ ì—¬ë¶€\n",
    "    if not match:\n",
    "        # [ì¬ê·€ ì¢…ë£Œ ì¡°ê±´] í•¨ìˆ˜ í˜¸ì¶œì´ ì—†ìœ¼ë©´, í˜„ì¬ í…ìŠ¤íŠ¸ê°€ ìµœì¢… ë‹µë³€ì„\n",
    "        print(\"ğŸ¤– AI íŒë‹¨: ì¼ë°˜ ë‹µë³€ (ì¬ê·€ ì¢…ë£Œ)\")\n",
    "        return output_text\n",
    "    else:\n",
    "        # [ì¬ê·€ í˜¸ì¶œ ì¡°ê±´] í•¨ìˆ˜ í˜¸ì¶œì´ ìˆìœ¼ë©´, ì¶”ê°€ ì²˜ë¦¬ í›„ ìì‹ ì„ ë‹¤ì‹œ í˜¸ì¶œ\n",
    "        print(f\"ğŸ¤– AI íŒë‹¨: í•¨ìˆ˜ í˜¸ì¶œ í•„ìš” (ë‚¨ì€ í˜¸ì¶œ íšŸìˆ˜: {max_depth-1})\")\n",
    "        function_call_string = match.group(0)\n",
    "        \n",
    "        try:\n",
    "            # 4-1. í•¨ìˆ˜ ì‹¤í–‰ ë° ê²°ê³¼ ì–»ê¸°\n",
    "            func_name = function_call_string.split('>')[0].split('=')[1]\n",
    "            args_str = function_call_string.split('>')[1].split('<')[0]\n",
    "            args_json = json.loads(args_str)\n",
    "            \n",
    "            result_data = None\n",
    "            if func_name == \"calculate_average\":\n",
    "                result_data = calculate_average(**args_json)\n",
    "            \n",
    "            # 4-2. ë‹¤ìŒ ì¬ê·€ í˜¸ì¶œì„ ìœ„í•œ ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
    "            # ì´ì „ ê¸°ë¡ì— LLMì˜ í•¨ìˆ˜ í˜¸ì¶œ ì‘ë‹µê³¼ ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì¶”ê°€\n",
    "            updated_messages = messages + [\n",
    "                {\"role\": \"assistant\", \"content\": output_text},\n",
    "                {\"role\": \"ipython\", \"content\": str(result_data)}\n",
    "            ]\n",
    "            \n",
    "            # 4-3. ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ê¸°ë¡ìœ¼ë¡œ ìê¸° ìì‹ ì„ ë‹¤ì‹œ í˜¸ì¶œ (ì¬ê·€)\n",
    "            return execute_llm_turn(messages=updated_messages, max_depth=max_depth - 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í•¨ìˆ˜ í˜¸ì¶œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return \"í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "def get_single_turn_response(user_query: str):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ìì˜ ì´ˆê¸° ì§ˆë¬¸ì„ ë°›ì•„ ì¬ê·€ í•¨ìˆ˜ì˜ ì‹¤í–‰ì„ ì‹œì‘í•˜ëŠ” ì§„ì…ì  í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸš€ ìƒˆ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: \\\"{user_query}\\\"\")\n",
    "    # 1. ì‚¬ìš©ìì˜ ì²« ì§ˆë¬¸ìœ¼ë¡œ ì´ˆê¸° ëŒ€í™” ê¸°ë¡ ìƒì„±\n",
    "    initial_messages = [{\"role\": \"user\", \"content\": user_query}]\n",
    "    # 2. ì¬ê·€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œì‘\n",
    "    return execute_llm_turn(messages=initial_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ca0f3-f345-4490-b484-5402e3bcad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_rag(user_query: str):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ RAGë¥¼ í†µí•´ ì°¾ì€ ì •ë³´ì™€ í•¨ê»˜ LLMì—ê²Œ ë‹µë³€ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- ì‚¬ìš©ì ì§ˆë¬¸: {user_query} ---\")\n",
    "    \n",
    "    # 1. Retrieve: RAG Retrieverë¡œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ë†’ì€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    retrieved_docs = rag_retriever.invoke(user_query)\n",
    "    print(f\"ğŸ“š {len(retrieved_docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 2. ì»¨í…ìŠ¤íŠ¸(Context) ìƒì„±: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "    context_data = \"\\n\".join([f\"- {doc.page_content}\" for doc in retrieved_docs])\n",
    "    '''\n",
    "    print(\"--- ê²€ìƒ‰ëœ RAG ë°ì´í„° ---\")\n",
    "    print(context_data)\n",
    "    print(\"-------------------------\")\n",
    "    '''\n",
    "    # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±: ê¸°ì¡´ì˜ í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ì§ˆë¬¸ê³¼ RAG ë°ì´í„°ë¥¼ ê²°í•©í•©ë‹ˆë‹¤.\n",
    "    # ì´ëŠ” get_single_turn_response í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ,\n",
    "    # í•´ë‹¹ í•¨ìˆ˜ì— ì „ë‹¬í•  í˜•íƒœë¡œ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "    final_query_for_llm = f\"\"\"\n",
    "    ì•„ë˜ [ë°ì´í„°]ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€ë‹µí•´ì£¼ì„¸ìš”.\n",
    "    \n",
    "    [ì§ˆë¬¸]\n",
    "    {user_query}\n",
    "\n",
    "    [ë°ì´í„°]\n",
    "    {context_data}\n",
    "    \"\"\"\n",
    "    \n",
    "    # 4. Generate: ì¬êµ¬ì„±ëœ ì§ˆë¬¸ì„ ê¸°ì¡´ì— ë§Œë“¤ì—ˆë˜ LLM í˜¸ì¶œ í•¨ìˆ˜ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "    final_answer = get_single_turn_response(final_query_for_llm)\n",
    "    \n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede3a58-e16c-4479-be1f-c977f7f76dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ì‹¤ì œ ì„œë¹„ìŠ¤ ë¡œì§ ì˜ˆì‹œ (Stateless) ---\n",
    "\n",
    "# Case 1: ì¼ë°˜ì ì¸ íŒŒì‹±\n",
    "print(\"--- Case 1: í•¨ìˆ˜ í˜¸ì¶œ ì§ˆë¬¸ ---\")\n",
    "user_input_1 = \"\"\n",
    "final_response_1 = answer_with_rag(user_input_1)\n",
    "print(\"\\n[ìµœì¢… ë‹µë³€]\")\n",
    "print(final_response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf790e-6ec9-4ed7-87fa-a262f0ad2a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
