{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b720e-3853-4381-a6ca-1539cd9d1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm RAG í”ŒëŸ¬ê·¸ì¸ ì„¤ì •(ì„ë² ë”©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d923a60-c928-4f3c-8683-2e6464c0ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ede17c-965c-4439-ab04-29e26f6bc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ìˆ˜ì •\n",
    "import pandas as pd\n",
    "from langchain_core.documents import Document # LangChainì˜ ê¸°ë³¸ ë¬¸ì„œ í˜•ì‹ì„ import\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc75f3-cde9-44b8-8ed4-bf2ef8ecdc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_pipeline_chroma(file_path: str, embedding_model_name: str, persist_directory: str):\n",
    "    \"\"\"\n",
    "    CSV íŒŒì¼ë¡œë¶€í„° ChromaDB RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê³  ê²€ìƒ‰ê¸°(Retriever)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # 1. Embed: ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ì´ì „ê³¼ ë™ì¼)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "    print(\"âœ… ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 2. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë˜ëŠ” ë¡œë“œ\n",
    "    # persist_directoryì— DBê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìƒˆë¡œ ë§Œë“¤ì§€ ì•Šê³  ë°”ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    if os.path.exists(persist_directory):\n",
    "        print(\"âœ… ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
    "        vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "    else:\n",
    "        print(\"âš ï¸ ê¸°ì¡´ ChromaDBê°€ ì—†ìœ¼ë¯€ë¡œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "        # 1. Pandasë¡œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        print(f\"âœ… Pandasë¡œ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì´ {len(df)}ê°œ í–‰)\")\n",
    "\n",
    "        # 2. ê° í–‰ì„ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜í•˜ê³ , LangChain 'Document' ê°ì²´ë¡œ ë§Œë“¤ê¸°\n",
    "        langchain_documents = []\n",
    "        for timestamp, values in df.iterrows():\n",
    "            # ì§ì ‘ ë§Œë“œì‹  ìì—°ì–´ ë³€í™˜ ë¡œì§\n",
    "            sentence = f\"'{timestamp}'ì˜ \"\n",
    "            value_strings = [f\"'{col}'ëŠ” {val}\" for col, val in values.items()]\n",
    "            sentence += \", \".join(value_strings)\n",
    "            \n",
    "            # ë³€í™˜ëœ ë¬¸ì¥ì„ page_contentë¡œ í•˜ëŠ” Document ê°ì²´ ìƒì„±\n",
    "            # metadataì— ì›ë³¸ ì‹œê°„ ì •ë³´ë¥¼ ë„£ì–´ë‘ë©´ ë‚˜ì¤‘ì— ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "            doc = Document(\n",
    "                page_content=sentence,\n",
    "                metadata={\"timestamp\": timestamp}\n",
    "            )\n",
    "            langchain_documents.append(doc)\n",
    "        \n",
    "        print(f\"âœ… {len(langchain_documents)}ê°œì˜ ìì—°ì–´ ë¬¸ì„œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # Store: ChromaDBë¥¼ ìƒì„±í•˜ê³  íŒŒì¼ë¡œ ì €ì¥(persist)í•©ë‹ˆë‹¤.\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=langchain_documents, \n",
    "            embedding=embeddings,\n",
    "            persist_directory=persist_directory # ì´ ê²½ë¡œì— DB íŒŒì¼ì´ ì €ì¥ë©ë‹ˆë‹¤.\n",
    "        )\n",
    "        print(f\"âœ… ChromaDBë¥¼ ìƒì„±í•˜ê³  '{persist_directory}' ê²½ë¡œì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 3. Retriever ìƒì„± (ì´ì „ê³¼ ì™„ë²½íˆ ë™ì¼)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    print(\"âœ… Retrieverë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ.\")\n",
    "    \n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1add9b-da27-4254-ac00-d6cbf5b337ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---\n",
    "CSV_FILE_PATH = 'RTDB_test.csv'\n",
    "EMBEDDING_MODEL = 'nlpai-lab/KURE-v1'\n",
    "CHROMA_DB_PATH = 'chroma_db' # DB íŒŒì¼ì´ ì €ì¥ë  í´ë” ì´ë¦„\n",
    "# ChromaDBìš© í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "rag_retriever = setup_rag_pipeline_chroma(CSV_FILE_PATH, EMBEDDING_MODEL, CHROMA_DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010a028-8615-46ab-afa6-b524db0f1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm ë©”ì¸ ëª¨ë¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97857f77-4393-48ca-8315-4ac149eacf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. GGUF ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ---\n",
    "# Hugging Face Hubì—ì„œ ì§€ì •ëœ ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name = \"jjkim110523/kanana-1.5-15.7b-a3b-instruct-Q4_K_M-GGUF\"\n",
    "model_file = \"kanana-1.5-15.7b-a3b-instruct-q4_k_m.gguf\"\n",
    "\n",
    "print(\"download!\")\n",
    "\n",
    "# progress barì™€ í•¨ê»˜ ë‹¤ìš´ë¡œë“œ ì§„í–‰\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=model_name,\n",
    "    filename=model_file,\n",
    "    local_dir=\"./models\" # ë‹¤ìš´ë¡œë“œ ë°›ì„ ë¡œì»¬ ê²½ë¡œ ì§€ì •\n",
    ")\n",
    "\n",
    "print(f\"Model downloaded to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14617795-4792-4b0d-b3bc-590eb653e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "import os\n",
    "from llama_cpp.llama_chat_format import Jinja2ChatFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f91b4a-f5d3-4fb6-a618-45305437283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Jinja ì±„íŒ… í…œí”Œë¦¿ íŒŒì¼ì—ì„œ ë¡œë“œ (ìˆ˜ì •ëœ ë¶€ë¶„) ---\n",
    "# 'lmalign_v1.jinja' íŒŒì¼ì´ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
    "jinja_template_path = \"lmalign_v1.jinja\"\n",
    "\n",
    "if not os.path.exists(jinja_template_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"'{jinja_template_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. \"\n",
    "        \"ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë””ë ‰í† ë¦¬ì— íŒŒì¼ì„ ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "with open(jinja_template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    jinja_template = f.read()\n",
    "\n",
    "# --- 3. Jinja2ChatFormatter ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---\n",
    "chat_handler = Jinja2ChatFormatter(\n",
    "    template=jinja_template,\n",
    "    eos_token=\"<|eot_id|>\",\n",
    "    bos_token=\"<|begin_of_text|>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2a974-9865-4998-ba47-daa5be210cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Llama ëª¨ë¸ ë¡œë“œ ---\n",
    "# ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ê³¼ íŒŒì¼ì—ì„œ ì½ì–´ì˜¨ Jinja í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "llm = Llama(\n",
    "  model_path=model_path,\n",
    "  n_ctx=8192,         # Context window ì‚¬ì´ì¦ˆ\n",
    "  n_gpu_layers=-1,    # GPU ê°€ì† ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "  verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af9560-3511-4519-b776-e8b265e6b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. ì¶”ë¡  ì‹¤í–‰ ---\n",
    "# ì„œë¹„ìŠ¤ ì„¤ëª… ë° ì¶œë ¥ í†µì œ ì§€ì‹œì‚¬í•­ì„ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "#ì¶”ê°€ í”„ë¡¬: - ë°˜ë“œì‹œ JSON í¬ë§·ìœ¼ë¡œ ì‘ë‹µ\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "\n",
    "[í•¨ìˆ˜(ë„êµ¬) ì‚¬ìš© ê·œì¹™ (Function/Tool Usage Rules)]\n",
    "- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í•´ê²°í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜(ë„êµ¬)ê°€ ìˆë‹¤ë©´, ë°˜ë“œì‹œ í•´ë‹¹ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. ì œê³µëœ ë°ì´í„°ì— ì •ë³´ê°€ ì—†ë‹¤ê³  í•´ì„œ ì¶”ì¸¡í•˜ì—¬ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "- í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ëŠ” ì ˆëŒ€ì ì¸ ì‚¬ì‹¤(ground truth)ë¡œ ê°„ì£¼í•˜ê³ , ì ˆëŒ€ ìŠ¤ìŠ¤ë¡œ ì¬ê³„ì‚°í•˜ê±°ë‚˜ ê²€ì¦í•˜ì§€ ë§ˆì„¸ìš”. ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê¸° ì „, ëŒ€í™” ê¸°ë¡ì„ ë¨¼ì € í™•ì¸í•˜ì—¬ ë™ì¼í•œ í•¨ìˆ˜ë¥¼ ë™ì¼í•œ ë§¤ê°œë³€ìˆ˜ë¡œ ì´ë¯¸ í˜¸ì¶œí•œ ì ì´ ìˆëŠ”ì§€ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ ì´ì „ì— ì–»ì€ ê²°ê³¼ê°€ ìˆë‹¤ë©´, ì ˆëŒ€ ë¶ˆí•„ìš”í•˜ê²Œ í•¨ìˆ˜ë¥¼ ë‹¤ì‹œ í˜¸ì¶œí•˜ì§€ ë§ê³  ê¸°ì¡´ ê²°ê³¼ë¥¼ ì¬ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c47b1e-d0a2-4a10-bdd8-62719acf3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Function Calling í…ŒìŠ¤íŠ¸ ---\n",
    "\n",
    "# 5-1. íŒŒì´ì¬ í•¨ìˆ˜ ì •ì˜\n",
    "# '-> float'ëŠ” ì´ í•¨ìˆ˜ê°€ ìˆ«ì(float)ë¥¼ ë°˜í™˜í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ëŠ” íƒ€ì… íŒíŠ¸ì…ë‹ˆë‹¤.\n",
    "def calculate_average(val1: float, val2: float) -> float:\n",
    "    \"\"\"ë‘ ê°œì˜ ìˆ«ì ê°’ì˜ ì‚°ìˆ  í‰ê· ì„ ê³„ì‚°í•˜ê³ , ê·¸ ìˆ«ì ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        average = (val1 + val2) / 2\n",
    "        print(f\"--- 'calculate_average' í˜¸ì¶œë¨ (val1={val1}, val2={val2}), ê²°ê³¼: {average} ---\")\n",
    "        return average # ğŸ‘ˆ ë¬¸ì¥ ëŒ€ì‹  ìˆ«ì ê°’ì„ ì§ì ‘ ë°˜í™˜\n",
    "    except TypeError:\n",
    "        return 0.0 # ì˜¤ë¥˜ ë°œìƒ ì‹œ 0.0 ë°˜í™˜\n",
    "\n",
    "# 5-2. Kanana ëª¨ë¸ì— ì•Œë ¤ì¤„ ë„êµ¬(í•¨ìˆ˜) ëª©ë¡ ì •ì˜ (OpenAI tool-call í˜•ì‹)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate_average\",\n",
    "            \"description\": \" task_Dì˜ ê°’ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜ë¡œ ì£¼ì–´ì§„ ì •ë³´ì—ì„œ í•´ë‹¹ ì‹œê°„ëŒ€ì˜ Aê°’ê³¼ Bì„ ì°¾ì•„ í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"val1\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"í•´ë‹¹ ì‹œê°„ëŒ€ì˜ A ê°’ì…ë‹ˆë‹¤.\"\n",
    "                    },\n",
    "                    \"val2\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"í•´ë‹¹ ì‹œê°„ëŒ€ì˜  B ê°’ì…ë‹ˆë‹¤.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"val1\", \"val2\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b903b-41f0-46f7-b9bf-42a330a652a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def execute_llm_turn(messages: list, max_depth: int = 5):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡(messages)ì„ ë°”íƒ•ìœ¼ë¡œ LLMì„ 1íšŒ í˜¸ì¶œí•˜ê³ ,\n",
    "    ê·¸ ê²°ê³¼ê°€ í•¨ìˆ˜ í˜¸ì¶œì´ë©´ ì¬ê·€ì ìœ¼ë¡œ ìì‹ ì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ëŠ” í•µì‹¬ í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    # 1. ì¬ê·€ í˜¸ì¶œì˜ ì•ˆì „ì¥ì¹˜: ìµœëŒ€ í˜¸ì¶œ íšŸìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜\n",
    "    if max_depth <= 0:\n",
    "        return \"ìµœëŒ€ í•¨ìˆ˜ í˜¸ì¶œ íšŸìˆ˜ë¥¼ ì´ˆê³¼í•˜ì—¬ ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "    # 2. ì£¼ì–´ì§„ messagesë¡œ LLM ì¶”ë¡  ì‹¤í–‰ (ì½”ë“œ ì¤‘ë³µ ì œê±°)\n",
    "    prompt_response = chat_handler(messages=messages, tools=tools)\n",
    "    response = llm.create_completion(\n",
    "        prompt=prompt_response.prompt,\n",
    "        max_tokens=2048,\n",
    "        stop=prompt_response.stop,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    output_text = response['choices'][0]['text'].strip()\n",
    "\n",
    "    # 3. LLMì˜ ì‘ë‹µì—ì„œ í•¨ìˆ˜ í˜¸ì¶œ íŒ¨í„´ í™•ì¸\n",
    "    match = re.search(r\"<function=.*?</function>\", output_text)\n",
    "\n",
    "    # 4. ì¬ê·€ì˜ ë¶„ê¸°ì : í•¨ìˆ˜ í˜¸ì¶œì´ ìˆëŠ”ì§€ ì—¬ë¶€\n",
    "    if not match:\n",
    "        # [ì¬ê·€ ì¢…ë£Œ ì¡°ê±´] í•¨ìˆ˜ í˜¸ì¶œì´ ì—†ìœ¼ë©´, í˜„ì¬ í…ìŠ¤íŠ¸ê°€ ìµœì¢… ë‹µë³€ì„\n",
    "        print(\"ğŸ¤– AI íŒë‹¨: ì¼ë°˜ ë‹µë³€ (ì¬ê·€ ì¢…ë£Œ)\")\n",
    "        return output_text\n",
    "    else:\n",
    "        # [ì¬ê·€ í˜¸ì¶œ ì¡°ê±´] í•¨ìˆ˜ í˜¸ì¶œì´ ìˆìœ¼ë©´, ì¶”ê°€ ì²˜ë¦¬ í›„ ìì‹ ì„ ë‹¤ì‹œ í˜¸ì¶œ\n",
    "        print(f\"ğŸ¤– AI íŒë‹¨: í•¨ìˆ˜ í˜¸ì¶œ í•„ìš” (ë‚¨ì€ í˜¸ì¶œ íšŸìˆ˜: {max_depth-1})\")\n",
    "        function_call_string = match.group(0)\n",
    "        \n",
    "        try:\n",
    "            # 4-1. í•¨ìˆ˜ ì‹¤í–‰ ë° ê²°ê³¼ ì–»ê¸°\n",
    "            func_name = function_call_string.split('>')[0].split('=')[1]\n",
    "            args_str = function_call_string.split('>')[1].split('<')[0]\n",
    "            args_json = json.loads(args_str)\n",
    "            \n",
    "            result_data = None\n",
    "            if func_name == \"calculate_average\":\n",
    "                result_data = calculate_average(**args_json)\n",
    "            \n",
    "            # 4-2. ë‹¤ìŒ ì¬ê·€ í˜¸ì¶œì„ ìœ„í•œ ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
    "            # ì´ì „ ê¸°ë¡ì— LLMì˜ í•¨ìˆ˜ í˜¸ì¶œ ì‘ë‹µê³¼ ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì¶”ê°€\n",
    "            updated_messages = messages + [\n",
    "                {\"role\": \"assistant\", \"content\": output_text},\n",
    "                {\"role\": \"ipython\", \"content\": str(result_data)}\n",
    "            ]\n",
    "            \n",
    "            # 4-3. ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ê¸°ë¡ìœ¼ë¡œ ìê¸° ìì‹ ì„ ë‹¤ì‹œ í˜¸ì¶œ (ì¬ê·€)\n",
    "            return execute_llm_turn(messages=updated_messages, max_depth=max_depth - 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í•¨ìˆ˜ í˜¸ì¶œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return \"í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "def get_single_turn_response(user_query: str):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ìì˜ ì´ˆê¸° ì§ˆë¬¸ì„ ë°›ì•„ ì¬ê·€ í•¨ìˆ˜ì˜ ì‹¤í–‰ì„ ì‹œì‘í•˜ëŠ” ì§„ì…ì  í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸš€ ìƒˆ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: \\\"{user_query}\\\"\")\n",
    "    # 1. ì‚¬ìš©ìì˜ ì²« ì§ˆë¬¸ìœ¼ë¡œ ì´ˆê¸° ëŒ€í™” ê¸°ë¡ ìƒì„±\n",
    "    initial_messages = [{\"role\": \"user\", \"content\": user_query}]\n",
    "    # 2. ì¬ê·€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œì‘\n",
    "    return execute_llm_turn(messages=initial_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ca0f3-f345-4490-b484-5402e3bcad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_rag(user_query: str):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ RAGë¥¼ í†µí•´ ì°¾ì€ ì •ë³´ì™€ í•¨ê»˜ LLMì—ê²Œ ë‹µë³€ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- ì‚¬ìš©ì ì§ˆë¬¸: {user_query} ---\")\n",
    "    \n",
    "    # 1. Retrieve: RAG Retrieverë¡œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ë†’ì€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    retrieved_docs = rag_retriever.invoke(user_query)\n",
    "    print(f\"ğŸ“š {len(retrieved_docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 2. ì»¨í…ìŠ¤íŠ¸(Context) ìƒì„±: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "    context_data = \"\\n\".join([f\"- {doc.page_content}\" for doc in retrieved_docs])\n",
    "    '''\n",
    "    print(\"--- ê²€ìƒ‰ëœ RAG ë°ì´í„° ---\")\n",
    "    print(context_data)\n",
    "    print(\"-------------------------\")\n",
    "    '''\n",
    "    # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±: ê¸°ì¡´ì˜ í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ì§ˆë¬¸ê³¼ RAG ë°ì´í„°ë¥¼ ê²°í•©í•©ë‹ˆë‹¤.\n",
    "    # ì´ëŠ” get_single_turn_response í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ,\n",
    "    # í•´ë‹¹ í•¨ìˆ˜ì— ì „ë‹¬í•  í˜•íƒœë¡œ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "    final_query_for_llm = f\"\"\"\n",
    "    ì•„ë˜ [ë°ì´í„°]ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€ë‹µí•´ì£¼ì„¸ìš”.\n",
    "    \n",
    "    [ì§ˆë¬¸]\n",
    "    {user_query}\n",
    "\n",
    "    [ë°ì´í„°]\n",
    "    {context_data}\n",
    "    \"\"\"\n",
    "    \n",
    "    # 4. Generate: ì¬êµ¬ì„±ëœ ì§ˆë¬¸ì„ ê¸°ì¡´ì— ë§Œë“¤ì—ˆë˜ LLM í˜¸ì¶œ í•¨ìˆ˜ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "    final_answer = get_single_turn_response(final_query_for_llm)\n",
    "    \n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede3a58-e16c-4479-be1f-c977f7f76dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ì‹¤ì œ ì„œë¹„ìŠ¤ ë¡œì§ ì˜ˆì‹œ (Stateless) ---\n",
    "\n",
    "# Case 1: ì¼ë°˜ì ì¸ íŒŒì‹±\n",
    "print(\"--- Case 1: í•¨ìˆ˜ í˜¸ì¶œ ì§ˆë¬¸ ---\")\n",
    "user_input_1 = \"\"\n",
    "final_response_1 = answer_with_rag(user_input_1)\n",
    "print(\"\\n[ìµœì¢… ë‹µë³€]\")\n",
    "print(final_response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf790e-6ec9-4ed7-87fa-a262f0ad2a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_venv",
   "language": "python",
   "name": "jupyter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
